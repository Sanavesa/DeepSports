{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from timesformer.models.vit import TimeSformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivingViT(nn.Module):\n",
    "    def __init__(self, pretrained_model, drop_prob=0.5, freeze=False, num_classes=1):\n",
    "        \"\"\"\n",
    "        Builds upon the TimeSformer model with additional MLP layers of (512 > 256 > num_classes).\n",
    "\n",
    "        Args:\n",
    "            pretrained_model (TimeSformer): A pretrained instance of TimeSformer of 8 frames and 224x224.\n",
    "            drop_prob (float, optional): Drop probability for dropout after the TimeSformer model. Defaults to 0.5.\n",
    "            freeze (bool, optional): Whether to freeze the pretrained model weights or also add them to the gradient updates. Defaults to False.\n",
    "            num_classes (int, optional): The number of output classes. Defaults to 1.\n",
    "        \"\"\"\n",
    "        super(DivingViT, self).__init__()\n",
    "        \n",
    "        self.pretrained_model = pretrained_model\n",
    "        if freeze:\n",
    "            pretrained_model.requires_grad_ = False\n",
    "            \n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "        self.linears = nn.Sequential(\n",
    "            nn.Linear(in_features=768, out_features=512),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.Linear(in_features=256, out_features=num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes the forward pass of the model. The input must be in the shape (batch, channels, frames, height, width).\n",
    "        The output will have the shape of (batch, num_classes).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input to the model. It is in the shape (batch, channels, frames, height, width).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Returns the output of the model. It is in the shape (batch, num_classes).\n",
    "        \"\"\"\n",
    "        out = self.pretrained_model(x) # (batch, 768)\n",
    "        out = self.dropout(out) # (batch, 768)\n",
    "        out = self.linears(out) # (batch, num_classes)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Found 341 in dataset/01.csv.\n",
      "Loaded 341 clips in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Convertor between PIL to Pytorch Tensor\n",
    "convert_tensor = transforms.ToTensor()\n",
    "\n",
    "# A data class to hold a single video clip\n",
    "class VideoClip:\n",
    "    PATH_TO_FRAMES = \"D:/MTL-AQA-Frames/\"\n",
    "    def __init__(self, video_num, start_frame, end_frame, difficulty, final_score):\n",
    "        self.video_num = video_num\n",
    "        self.start_frame = start_frame\n",
    "        self.end_frame = end_frame\n",
    "        self.difficulty = difficulty\n",
    "        self.final_score = final_score\n",
    "    \n",
    "    def load(self):\n",
    "        # Computes the number of frames in the clip\n",
    "        clip_num_frames = self.end_frame - self.start_frame + 1\n",
    "        \n",
    "        # Creates the video clip in torch with (channels x frames x height x width)\n",
    "        clip = torch.empty(size=(3, 8, 224, 224), dtype=torch.float32)\n",
    "        \n",
    "        # Since we are constrained to 8 frames, pick 8 frames from the entire clip\n",
    "        step_size = clip_num_frames // 8 + 1\n",
    "        for idx, frame_num in enumerate(range(self.start_frame, self.end_frame + 1, step_size)):\n",
    "            img_path = VideoClip.PATH_TO_FRAMES + f\"{self.video_num:02d}/{frame_num:06d}.jpg\"\n",
    "            img = Image.open(img_path).resize((224, 224))\n",
    "            tensor = convert_tensor(img).type(dtype=torch.float32) # (channels x height x width)\n",
    "            clip[:, idx, :, :] = tensor\n",
    "        \n",
    "        # Generate the outputs/targets for this clip\n",
    "        target = torch.tensor([self.final_score], dtype=torch.float32)\n",
    "        return clip, target\n",
    "\n",
    "clips_dataset = []\n",
    "print(f\"Loading dataset...\")\n",
    "\n",
    "# Loads all the video clips from the dataset textfile that Mohammad generates. They're in the format video_num,start_frame,end_frame,difficulty,final_score\n",
    "# where video_num is the video number it came from (01.mp4 is 1, 02.mp4 is 2, etc.)\n",
    "def load_dataset_file(filename):\n",
    "    loaded_clips = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        # Read all lines, but skip the header\n",
    "        for line in f.readlines()[1:]:\n",
    "            # format: video_num,start_frame,end_frame,difficulty,final_score\n",
    "            split = line.split(\",\")\n",
    "            \n",
    "            # TODO: Add better checking and error handling\n",
    "            video_num = int(split[0])\n",
    "            start_frame = int(split[1])\n",
    "            end_frame = int(split[2])\n",
    "            difficulty = float(split[3])\n",
    "            final_score = float(split[4])\n",
    "            loaded_clips.append(VideoClip(video_num, start_frame, end_frame, difficulty, final_score))\n",
    "    print(f\"Found {len(loaded_clips)} in {filename}.\")\n",
    "    return loaded_clips\n",
    "\n",
    "clips_dataset.extend(load_dataset_file(\"dataset/01.csv\"))\n",
    "# clips_dataset.extend(load_dataset_file(\"dataset/02.csv\"))\n",
    "# clips_dataset.extend(load_dataset_file(\"dataset/03.csv\"))\n",
    "# clips_dataset.extend(load_dataset_file(\"dataset/04.csv\"))\n",
    "\n",
    "print(f\"Loaded {len(clips_dataset)} clips in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, clips_dataset):\n",
    "        self.clips_dataset = clips_dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.clips_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.clips_dataset[index].load()\n",
    "\n",
    "train_dataset = MyDataset(clips_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 \t train_loss: 4116.3033\n",
      "Epoch 2/3 \t train_loss: 399.7047\n",
      "Epoch 3/3 \t train_loss: 227.0480\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 3\n",
    "learning_rate = 1e-5\n",
    "\n",
    "path = \"D:/Programming/Github/DeepSports/training/TimeSformer/TimeSformer_divST_8x32_224_K400.pyth\"\n",
    "pretrained_model = TimeSformer(img_size=224, num_classes=768, num_frames=8, attention_type='divided_space_time',  pretrained_model=path)\n",
    "model = DivingViT(pretrained_model, drop_prob=0.5, freeze=False, num_classes=1).to(device)\n",
    "\n",
    "opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "plot_data = {\n",
    "    \"train_loss\": []\n",
    "}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = []\n",
    "    \n",
    "    # Training\n",
    "    for (inputs, targets) in train_data_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss.append(loss.item())\n",
    "    print(f\"Epoch {epoch+1}/{epochs} \\t train_loss: {np.mean(train_loss):.4f}\")\n",
    "    plot_data[\"train_loss\"].append(np.mean(train_loss))\n",
    "    \n",
    "    # Validation every 10th epoch\n",
    "    # if epoch % 10 == 0:\n",
    "    #     val_loss = []\n",
    "    #     with torch.no_grad():\n",
    "    #         for (inputs, targets) in train_data_loader:\n",
    "    #             inputs, targets = inputs.to(device), targets.to(device)\n",
    "    #             outputs = model(inputs)\n",
    "    #             loss = criterion(outputs, targets)\n",
    "    #             val_loss.append(loss.item())\n",
    "    #             print('Outputs', outputs)\n",
    "    #             print('Targets', targets)\n",
    "    #     print(f\"Epoch {epoch+1}/{epochs} \\t val_loss: {np.mean(val_loss):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "epochs_range = list(range(1, epochs+1))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.plot(epochs_range, plot_data[\"train_loss\"], label=\"train_loss\")\n",
    "ax1.title.set_text(\"Loss\")\n",
    "ax1.legend()\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 78.69\tExpected 95.20\n",
      "Predicted 70.64\tExpected 81.60\n",
      "Predicted 78.81\tExpected 72.00\n",
      "Predicted 73.27\tExpected 54.45\n",
      "Predicted 71.59\tExpected 51.20\n",
      "Predicted 73.76\tExpected 81.00\n",
      "Predicted 74.83\tExpected 66.00\n",
      "Predicted 74.24\tExpected 54.45\n",
      "Predicted 74.86\tExpected 70.20\n",
      "Predicted 73.65\tExpected 76.50\n",
      "Predicted 73.97\tExpected 44.55\n",
      "Predicted 73.94\tExpected 37.95\n",
      "Predicted 73.94\tExpected 64.35\n",
      "Predicted 74.32\tExpected 67.20\n",
      "Predicted 78.96\tExpected 84.15\n",
      "Predicted 71.92\tExpected 97.20\n",
      "Predicted 76.02\tExpected 85.80\n",
      "Predicted 74.57\tExpected 37.70\n",
      "Predicted 75.66\tExpected 49.50\n",
      "Predicted 75.59\tExpected 37.95\n",
      "Predicted 74.17\tExpected 93.60\n",
      "Predicted 74.65\tExpected 59.40\n",
      "Predicted 71.64\tExpected 76.50\n",
      "Predicted 75.32\tExpected 62.40\n",
      "Predicted 74.71\tExpected 66.60\n",
      "Predicted 75.42\tExpected 64.35\n",
      "Predicted 76.58\tExpected 81.60\n",
      "Predicted 74.10\tExpected 72.00\n",
      "Predicted 68.19\tExpected 89.10\n",
      "Predicted 74.35\tExpected 86.40\n",
      "Epoch 3/3 \t val_loss: 228.4892\n"
     ]
    }
   ],
   "source": [
    "# See how the predictions were close to the real value\n",
    "val_loss = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    _outputs = []\n",
    "    _targets = []\n",
    "    for (inputs, targets) in train_data_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        val_loss.append(loss.item())\n",
    "        \n",
    "        # TODO: This is bad code!\n",
    "        _outputs.append(outputs[0].item())\n",
    "        _targets.append(targets[0].item())\n",
    "    \n",
    "    for i in range(min(30, len(_outputs))): # Use this for loop to show some of the predictions\n",
    "    # for i in range(len(_outputs)): # Use this for loop to show ALL predictions\n",
    "        print(f\"Predicted {_outputs[i]:.2f}\\tExpected {_targets[i]:.2f}\")\n",
    "\n",
    "print(f\"Epoch {epoch+1}/{epochs} \\t val_loss: {np.mean(val_loss):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b89f1b84983c559dac739733dcea4ad2abe6dead7bb9096ab1b6c922cc3d892"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
